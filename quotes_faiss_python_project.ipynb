{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: pinecone-client in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: openai in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (1.30.1)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (8.1.2)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (0.1.7)\n",
      "Collecting astor\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from langchain-community) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from langchain-community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from langchain-community) (0.6.6)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from langchain-community) (0.2.0)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from langchain-community) (0.2.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from langchain-community) (0.1.60)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from langchain-community) (2.32.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from langchain-community) (8.3.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from pinecone-client) (2024.2.2)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from pinecone-client) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from pinecone-client) (4.11.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from pinecone-client) (2.2.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from openai) (2.7.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from tiktoken) (2024.5.15)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from ipywidgets) (8.24.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from langchain<0.3.0,>=0.2.0->langchain-community) (0.2.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain-community) (2.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\khale\\machine_learning\\.venv\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Installing collected packages: astor\n",
      "Successfully installed astor-0.8.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-community pinecone-client openai tiktoken ipywidgets -U langchain-openai astor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import ast\n",
    "import astor\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment variables from .env file\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "EMBEDDINGS_SIZE_LARGE = 3072\n",
    "EMBEDDINGS_SIZE_SMALL = 1536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_content(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.Client(api_key=OPENAI_API_KEY)\n",
    "\n",
    "def summarize_file(file_path):\n",
    "    data = get_file_content(file_path)\n",
    "    completion = client.chat.completions.create(\n",
    "      model=\"gpt-4-turbo\",\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": \"You are an assistant trained to summarize code files succinctly. When given a file, provide a brief summary without any introductions or additional text.\"},\n",
    "          {\"role\": \"user\", \"content\": \"Please summarize the following file:\\n\\n\" + data}\n",
    "      ]\n",
    "    )\n",
    "    \n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_router.py\n"
     ]
    }
   ],
   "source": [
    "file = get_file_content(\"./Smarderobe/server/app/routers/user_router.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from app.database.schemas import UserSchema, UserOutSchema, ResetPasswordSchema, ResetPasswordRequestScheam\\nfrom sqlalchemy import select, insert, delete, update, exc\\nfrom sqlalchemy.orm import Session, selectinload\\nfrom app.db_setup import get_db\\nfrom fastapi import Request, Depends, APIRouter, HTTPException, status\\nfrom app.database.models import User, Profile\\nfrom app.auth import get_password_hash, get_user_id, create_access_token,  SECRET_KEY, ALGORITHM, oauth2_scheme, credentials_exception, ACCESS_TOKEN_EXPIRE_MINUTES\\nfrom app.logging.logger import logger\\nfrom typing import Annotated\\nfrom app.send_email import  send_verification_email\\nfrom app.config import backend_base_url, frontend_base_url\\nfrom datetime import timedelta\\nfrom app.send_email import env\\nfrom fastapi.templating import Jinja2Templates\\nfrom fastapi.responses import HTMLResponse\\nfrom jose import JWTError, jwt\\n\\nrouter = APIRouter()\\n\\ntemplates = Jinja2Templates(directory=\"./app/templates\")\\n\\n@router.post(\"/\", status_code=201)\\nasync def create_user( new_user: UserSchema, db: Session = Depends(get_db)) -> UserOutSchema:\\n    try:\\n        hashed_password= get_password_hash(new_user.password)\\n        new_user.password = hashed_password\\n        created_user = User(**new_user.model_dump())\\n        db.add(created_user)\\n        db.commit()\\n        profile =  {\\n            \"user_id\": created_user.id,\\n            \"name\": f\"{created_user.first_name} {created_user.last_name}\"\\n        }\\n        created_profile = Profile(**profile)\\n        db.add(created_profile)\\n        db.commit()\\n        token_expiration_time = timedelta(minutes=5)\\n        validation_token = create_access_token(user={\"id\": created_user.id}, expires_delta=token_expiration_time)\\n        validation_url = f\"{backend_base_url}/v1/users/verification/{validation_token}\"\\n        await send_verification_email(subject=\"Verify your account\", email_to=new_user.email ,body={\\'title\\': \\'Verification\\', \\'name\\': f\"{new_user.first_name} {new_user.last_name}\", \"link\":validation_url })\\n        return created_user\\n\\n    except exc.IntegrityError as e:\\n        logger.error(e)\\n        db.rollback()  # Rollback the session to avoid transaction stuck\\n        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"Account with this email already exists.\")\\n\\n\\n@router.get(\"/\", status_code=200)\\ndef list_users(db: Session = Depends(get_db)):\\n    \"\"\"\\n    Fetches all users\\n    \"\"\"\\n    result = db.scalars(select(User).options(selectinload(User.profile))).all()\\n    if not result:\\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"No users login credentials found\")\\n    return result\\n\\n\\n@router.get(\"/me\")\\nasync def get_user(user_id: Annotated[int, Depends(get_user_id)], db: Session=Depends(get_db)) -> UserOutSchema:\\n    user = db.scalars(select(User).where(User.id == user_id).options(selectinload(User.profile))).first()\\n    if user is None:\\n        raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"Unauthorized\")\\n    return user\\n\\n\\n@router.get(\"/validation\")\\ndef get_email_validation_status(user_id: Annotated[int, Depends(get_user_id)], db: Session = Depends(get_db)):\\n    query  = select(User).where(User.id == user_id)\\n    db_user = db.scalars(query).first()\\n    return {\"verified\": db_user.email_verified}\\n\\n\\n# Resend verification email\\n@router.post(\"/verification\")\\nasync def send_validation_email(user_id: Annotated[int, Depends(get_user_id)], db: Session=Depends(get_db)):\\n    db_user = db.scalars(select(User).where(User.id == user_id)).first()\\n    token_expiration_time = timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)\\n    validation_token = create_access_token(user={\"id\": user_id}, expires_delta=token_expiration_time)\\n    validation_url = f\"{backend_base_url}/v1/users/verification/{validation_token}\"\\n    await send_verification_email(subject=\"Verify your account\", email_to=db_user.email ,body={\\'title\\': \\'Verification\\', \\'name\\': f\"{db_user.first_name} {db_user.last_name}\", \"link\":validation_url })\\n    return {\"message\": \"Verification email sent\"}\\n\\n\\n\\n@router.get(\"/verification/{token}\", response_class=HTMLResponse)\\ndef validate_user(token: str,request: Request, db: Session = Depends(get_db)):\\n    try:\\n        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])\\n        user_id: int = payload.get(\"id\")\\n        query = select(User).where(User.id == user_id)\\n        db_user = db.scalars(query).first()\\n        if not db_user:\\n            raise HTTPException(status_code=404, detail=\"User not found\")\\n        db_user.email_verified = True\\n        db.commit()\\n        return templates.TemplateResponse(\\n            request=request, name=\"account_verified.html\" , context={\"message\": \"Your account has been verified.\"}\\n        )\\n    except JWTError:\\n        return templates.TemplateResponse(\\n            request=request, name=\"account_verified.html\" , context={\"message\": \"Token is not valid.\"}\\n        )\\n    except Exception:\\n        return templates.TemplateResponse(\\n            request=request, name=\"account_verified.html\" , context={\"message\": \"Sorry, Something went wrong!\"}\\n        )\\n\\n# User request to get reset password email\\n@router.post(\"/reset-password-request\")\\nasync def reset_password_request(data: ResetPasswordRequestScheam, db: Session= Depends(get_db)):\\n    db_user = db.scalars(select(User).where(User.email == data.email)).first()\\n    if db_user:\\n        token_expiration_time = timedelta(minutes=5)\\n        validation_token = create_access_token(user={\"id\": db_user.id, \"email\":db_user.email}, expires_delta=token_expiration_time)\\n        # The url of frontend reset password page\\n        pwd_reset_url = f\"{frontend_base_url}/reset-password/{validation_token}\"\\n        await send_verification_email(subject=\"Reset password\", email_to=db_user.email ,body={\\'title\\': \\'Reset your passwrod\\', \\'name\\': f\"{db_user.first_name} {db_user.last_name}\", \"link\":pwd_reset_url })\\n        return {\"message\": \"email sent\"}\\n    else:\\n        raise HTTPException(status_code= status.HTTP_400_BAD_REQUEST, detail= \"Email is not registered\")\\n\\n@router.post(\"/reset-password\")\\ndef reset_password(data: ResetPasswordSchema, token: Annotated[str, Depends(oauth2_scheme)], db: Session = Depends(get_db)):\\n    try:\\n        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])\\n        user_id: int = payload.get(\"id\")\\n        db_user = db.scalars(select(User).where(User.id == user_id)).first()\\n        if not db_user:\\n            raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail= \"User does not exist\")\\n        hashed_password= get_password_hash(data.password)\\n        db_user.password = hashed_password\\n        db.add(db_user)\\n        db.commit()\\n        return {\"message\": \"user password updated\"}\\n    except JWTError:\\n        raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"Your session has expired, please send another request to reset your password.\")\\n\\n\\n@router.get(\"/refresh-token\")\\ndef refresh_token(user_id: Annotated[int, Depends(get_user_id)]):\\n    token_expiration_time = timedelta(minutes=5)\\n    token = create_access_token(user={\"id\": user_id}, expires_delta=token_expiration_time)\\n    return {\"token\": token}\\n\\n@router.get(\"/{user_id}\", status_code=200)\\ndef list_users(user_id: int, db: Session = Depends(get_db)):\\n    \"\"\"\\n    Fetches one user based on user_id\\n    \"\"\"\\n    result = db.scalars(select(User).where(User.id == user_id).options(selectinload(User.profile))).first()\\n    if not result:\\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"No users login credentials found\")\\n    return result # Returns the password for now. Passwords needs to be hashed.\\n\\n@router.delete(\"/{users_id}\", status_code=status.HTTP_204_NO_CONTENT)\\ndef delete_users(users_id: int, db: Session = Depends(get_db)):\\n    \"\"\"\\n    Deletes a user based on an id\\n    \"\"\"\\n    query = delete(User).where(User.id == users_id)\\n    db.execute(query)\\n    db.commit()\\n    if query is None:\\n        raise HTTPException(status_code=404, detail=\"User not found\")'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summarize_file(\"./Smarderobe/server/app/routers/user_router.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The file defines API endpoints for a user management system using FastAPI, handling user creation, listing, validation, password reset requests, refreshing tokens, and deletion through various routes. It interacts with a database using SQLAlchemy to perform operations like adding a new user, getting user details, and verifying user emails. The endpoints use schemas for input validation, send emails for verification and password resets, and handle exceptions appropriately, providing responses based on the outcome of the operations. Additionally, token-based verification is employed for email verification and password reset functionalities. The system logs errors and uses templates for email responses.'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import astor\n",
    "import os\n",
    "\n",
    "class CodeVisitor(ast.NodeVisitor):\n",
    "    def __init__(self):\n",
    "        self.code_elements = []\n",
    "\n",
    "    \n",
    "    # def visit_Import(self, node):\n",
    "    #     self.elements.append(node)  # Store the AST node directly\n",
    "\n",
    "    # def visit_ImportFrom(self, node):\n",
    "    #     self.elements.append(node)  # Store the AST node directly\n",
    "\n",
    "    # # If you want to process body items as well\n",
    "    # def visit_Assign(self, node):\n",
    "    #     self.elements.append(node)  # Store assignment nodes\n",
    "\n",
    "    # def visit_Expr(self, node):\n",
    "    #     self.elements.append(node)  # Store expression nodes\n",
    "\n",
    "    # def visit_Return(self, node):\n",
    "    #     self.elements.append(node)  # Store return nodes\n",
    "\n",
    "    def visit_FunctionDef(self, node):\n",
    "        # Store function source code and metadata\n",
    "        self.code_elements.append({\n",
    "            \"page_content\": astor.to_source(node),\n",
    "            \"metadata\": {\n",
    "                \"type\": \"function\",\n",
    "                \"name\": node.name\n",
    "            }\n",
    "        })\n",
    "\n",
    "    def visit_ClassDef(self, node):\n",
    "        # Store the class itself\n",
    "        self.code_elements.append({\n",
    "            \"page_content\": astor.to_source(node),\n",
    "            \"metadata\": {\n",
    "                \"type\": \"class\",\n",
    "                \"name\": node.name\n",
    "            }\n",
    "        })\n",
    "        # Also visit methods within the class\n",
    "        method_visitor = CodeVisitor()\n",
    "        for n in node.body:\n",
    "            if isinstance(n, ast.FunctionDef):\n",
    "                method_visitor.visit(n)\n",
    "        self.code_elements.extend(method_visitor.code_elements)\n",
    "\n",
    "def parse_code_from_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        source_code = file.read()\n",
    "    tree = ast.parse(source_code)\n",
    "    visitor = CodeVisitor()\n",
    "    visitor.visit(tree)\n",
    "    return [\n",
    "        {**element, \"metadata\": {**element[\"metadata\"], \"source\": os.path.normpath(file_path)}}\n",
    "        for element in visitor.code_elements\n",
    "    ]\n",
    "\n",
    "def traverse_directory(directory):\n",
    "    all_code_elements = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.py'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                normalized_path = os.path.normpath(file_path)\n",
    "                # get summaries about the file content from chatGPT\n",
    "                file_summary =         {\n",
    "                    \"page_content\": summarize_file(file_path),\n",
    "                    \"metadata\": {\n",
    "                        \"source\": normalized_path,\n",
    "                        \"type\": \"summary\",\n",
    "                        \"name\":  normalized_path.split('\\\\')[-1]\n",
    "                    }\n",
    "                }\n",
    "                all_code_elements.append(file_summary)\n",
    "                code_elements = parse_code_from_file(file_path)\n",
    "                all_code_elements.extend(code_elements)\n",
    "    return all_code_elements\n",
    "\n",
    "# Example usage\n",
    "project_directory = \"./Smarderobe/server\"\n",
    "all_code_details = traverse_directory(project_directory)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt_files_descriptions():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files_descriptions = get_gpt_files_descriptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings( model =\"text-embedding-3-large\", openai_api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to initialize a FAISS vector store from documents\n",
    "def create_faiss_library(documents):\n",
    "    texts = [d['page_content'] for d in documents]\n",
    "    metadatas = [d['metadata'] for d in documents]\n",
    "    # Adjust the following line if the FAISS library API differs\n",
    "    return FAISS.from_texts(texts,  metadatas=metadatas, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "library = create_faiss_library(all_code_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"user class summary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_answer = library.similarity_search(query, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content=\"@router.get('/verification/{token}', response_class=HTMLResponse)\\ndef validate_user(token: str, request: Request, db: Session=Depends(get_db)):\\n    try:\\n        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])\\n        user_id: int = payload.get('id')\\n        query = select(User).where(User.id == user_id)\\n        db_user = db.scalars(query).first()\\n        if not db_user:\\n            raise HTTPException(status_code=404, detail='User not found')\\n        db_user.email_verified = True\\n        db.commit()\\n        return templates.TemplateResponse(request=request, name=\\n            'account_verified.html', context={'message':\\n            'Your account has been verified.'})\\n    except JWTError:\\n        return templates.TemplateResponse(request=request, name=\\n            'account_verified.html', context={'message': 'Token is not valid.'}\\n            )\\n    except Exception:\\n        return templates.TemplateResponse(request=request, name=\\n            'account_verified.html', context={'message':\\n            'Sorry, Something went wrong!'})\\n\" metadata={'type': 'function', 'name': 'validate_user', 'source': 'Smarderobe\\\\server\\\\app\\\\routers\\\\user_router.py'}\n"
     ]
    }
   ],
   "source": [
    "print(query_answer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class UserOutSchema(BaseModel):\n",
      "    first_name: str = Field(..., min_length=1, max_length=100)\n",
      "    last_name: str = Field(..., min_length=1, max_length=100)\n",
      "    email: EmailStr = Field(..., min_length=1, max_length=50, description=\n",
      "        'Email has to be Unique and is required.')\n",
      "    email_verified: bool\n",
      "    is_active: bool\n",
      "    id: int\n",
      "    profile: Optional[ProfileSchema]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(query_answer[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'Smarderobe\\\\server\\\\app\\\\database\\\\models\\\\profile.py', 'type': 'summary', 'name': 'profile.py'}\n",
      "Smarderobe\\server\\app\\database\\models\\profile.py\n",
      "summary\n",
      "profile.py\n",
      "The Python file defines a `Profile` class that extends from a `Base` class, representing a table named \"profiles\" in a database using SQLAlchemy ORM. The class includes a variety of optional attributes such as `name`, `username`, `description`, `profile_picture_url`, as well as body measurements like `height`, `waist`, `arms`, `legs`, `feet`, and `measurement_unit`. The model establishes relationships with a `User`, `Gender`, and `Address` model, each linked through foreign keys and incorporating considerations for deletion (e.g., setting foreign key references to NULL on delete). The profile is uniquely identified by the `user_id`. The `__repr__` method provides a string representation of the instance, formatted to display the profile name.\n",
      "\n",
      "\n",
      "{'source': 'Smarderobe\\\\server\\\\app\\\\database\\\\schemas\\\\__init__.py', 'type': 'summary', 'name': '__init__.py'}\n",
      "Smarderobe\\server\\app\\database\\schemas\\__init__.py\n",
      "summary\n",
      "__init__.py\n",
      "The file imports various schema classes related to an e-commerce or retail application dealing with users, clothing items, and profiles. It includes schema definitions for addresses, body sections, brands, categories, genders, seasons, clothing items, users, and user profiles. Each schema likely defines the structure of data for their respective entities in the system, including specific \"out\" schemas for output data formatting and specialized schemas for operations like updating user profiles or clothing items, and handling user authentication and password reset processes.\n",
      "\n",
      "\n",
      "{'source': 'Smarderobe\\\\server\\\\app\\\\database\\\\models\\\\user.py', 'type': 'summary', 'name': 'user.py'}\n",
      "Smarderobe\\server\\app\\database\\models\\user.py\n",
      "summary\n",
      "user.py\n",
      "The file defines a SQLAlchemy ORM model for a `User` within a system. The `User` class inherits from a base model and sets up its database table with the name \"users\". Attributes include `first_name`, `last_name`, `email`, `password`, `is_active`, `email_verified`, `access_token`, and `token_type` with appropriate database column types and constraints such as string length and uniqueness. Relationships are established to a `Profile` model and a list of `ClothingItem` models, with cascade options configured for the clothing items. The `__repr__` method provides a string representation that includes the user's email.\n",
      "\n",
      "\n",
      "{'source': 'Smarderobe\\\\server\\\\app\\\\database\\\\__init__.py', 'type': 'summary', 'name': '__init__.py'}\n",
      "Smarderobe\\server\\app\\database\\__init__.py\n",
      "summary\n",
      "__init__.py\n",
      "As there is no code provided in your request, I'm unable to provide a summary. Please provide the code content you need summarized.\n",
      "\n",
      "\n",
      "{'type': 'class', 'name': 'User', 'source': 'Smarderobe\\\\server\\\\app\\\\database\\\\models\\\\user.py'}\n",
      "Smarderobe\\server\\app\\database\\models\\user.py\n",
      "class\n",
      "User\n",
      "class User(Base):\n",
      "    __tablename__ = 'users'\n",
      "    first_name: Mapped[str] = mapped_column(String(100), nullable=False)\n",
      "    last_name: Mapped[str] = mapped_column(String(100), nullable=False)\n",
      "    email: Mapped[str] = mapped_column(String(100), unique=True, nullable=False\n",
      "        )\n",
      "    password: Mapped[str] = mapped_column(String(100), nullable=False)\n",
      "    is_active: Mapped[bool] = mapped_column(default=True)\n",
      "    email_verified: Mapped[bool] = mapped_column(default=False)\n",
      "    access_token: Mapped[str] = mapped_column(nullable=True)\n",
      "    token_type: Mapped[str] = mapped_column(nullable=True)\n",
      "    profile: Mapped['Profile'] = relationship('Profile', back_populates='user')\n",
      "    clothing_items: Mapped[list['ClothingItem']] = relationship(back_populates\n",
      "        ='user', cascade='all')\n",
      "\n",
      "    def __repr__(self):\n",
      "        return f'<User={self.email}>'\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for answer in query_answer:\n",
    "    print(answer.metadata)\n",
    "    print(answer.metadata['source'])\n",
    "    print(answer.metadata['type'])\n",
    "    print(answer.metadata['name'])\n",
    "    print(answer.page_content)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = \"upload image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2_answer = library.similarity_search(query2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smarderobe\\server\\app\\routers\\clothing_item_router.py\n",
      "def upload_image(file: UploadFile, IMAGEDIR: str) ->str:\n",
      "    filename = f\"{uuid4()}.{file.filename.split('.')[-1]}\"\n",
      "    file_path = os.path.join(IMAGEDIR, filename)\n",
      "    with open(file_path, 'wb') as f:\n",
      "        for chunk in file.file:\n",
      "            f.write(chunk)\n",
      "    return filename\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(query2_answer[0].metadata['source'])\n",
    "print(query2_answer[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smarderobe\\server\\app\\routers\\clothing_item_router.py\n",
      "def upload_image(file: UploadFile, IMAGEDIR: str) ->str:\n",
      "    filename = f\"{uuid4()}.{file.filename.split('.')[-1]}\"\n",
      "    file_path = os.path.join(IMAGEDIR, filename)\n",
      "    with open(file_path, 'wb') as f:\n",
      "        for chunk in file.file:\n",
      "            f.write(chunk)\n",
      "    return filename\n",
      "\n",
      "\n",
      "\n",
      "Smarderobe\\server\\app\\routers\\clothing_item_router.py\n",
      "@router.post('/', status_code=201)\n",
      "def add_clothing_item(user_id: Annotated[int, Depends(get_user_id)], name:\n",
      "    str=Form(...), description: str=Form(None), colours: str=Form(...),\n",
      "    size: str=Form(...), type: str=Form(None), brand_id: int=Form(...),\n",
      "    file: UploadFile=File(...), db: Session=Depends(get_db)):\n",
      "    if file.filename.split('.')[-1].lower() not in ['jpg', 'jpeg', 'bmp',\n",
      "        'webp', 'png']:\n",
      "        raise HTTPException(status_code=400, detail=\n",
      "            'Image extension is not supported')\n",
      "    type_id = db.scalars(Select(Type.id).where(Type.name == type)).first()\n",
      "    clothing_item_dict = {'name': name, 'description': description, 'size':\n",
      "        size, 'user_id': user_id, 'type_id': type_id, 'brand_id': brand_id}\n",
      "    db_clothing_item = ClothingItem(**clothing_item_dict)\n",
      "    db.add(db_clothing_item)\n",
      "    db.flush()\n",
      "    image_filename = upload_image(file, IMAGEDIR)\n",
      "    db_item_image = ItemImage(url=f'{image_filename}', clothing_item=\n",
      "        db_clothing_item)\n",
      "    db.add(db_item_image)\n",
      "    colors_list = [color_name.strip().lower() for color_name in colours.\n",
      "        split(',')]\n",
      "    for color_name in colors_list:\n",
      "        color = db.query(Color).filter(Color.name == color_name).first()\n",
      "        if color:\n",
      "            db.add(ClothingItemColor(clothing_item_id=db_clothing_item.id,\n",
      "                color_id=color.id))\n",
      "        else:\n",
      "            db.rollback()\n",
      "            raise HTTPException(status_code=400, detail=\n",
      "                f\"Color '{color_name}' does not exist in the database\")\n",
      "    db.commit()\n",
      "    db.refresh(db_clothing_item)\n",
      "    db.refresh(db_item_image)\n",
      "    return {'clothing_item_id': db_clothing_item.id, 'clothing_item_name':\n",
      "        db_clothing_item.name, 'image_url': db_item_image.url}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for answer in query2_answer:\n",
    "    print(answer.metadata[\"source\"])\n",
    "    print(answer.page_content)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smarderobe\\server\\app\\routers\\clothing_item_router.py\n",
      "def list_clothing_items(db): Expression: Constant(value='\\n    Get all clothing items\\n    ') Assign: Name(id='result', ctx=Store()) = Call(func=Attribute(value=Call(func=Attribute(value=Name(id='db', ctx=Load()), attr='scalars', ctx=Load()), args=[Call(func=Attribute(value=Call(func=Name(id='Select', ctx=Load()), args=[Name(id='ClothingItem', ctx=Load())], keywords=[]), attr='options', ctx=Load()), args=[Call(func=Name(id='selectinload', ctx=Load()), args=[Attribute(value=Name(id='ClothingItem', ctx=Load()), attr='item_images', ctx=Load())], keywords=[])], keywords=[])], keywords=[]), attr='all', ctx=Load()), args=[], keywords=[]) If Return: Name(id='result', ctx=Load()) def list_clothing_items(clothing_id, db): Expression: Constant(value='\\n    Get one clothing item based on its id\\n    ') Assign: Name(id='result', ctx=Store()) = Call(func=Attribute(value=Call(func=Attribute(value=Name(id='db', ctx=Load()), attr='scalars', ctx=Load()), args=[Call(func=Attribute(value=Call(func=Attribute(value=Call(func=Name(id='Select', ctx=Load()), args=[Name(id='ClothingItem', ctx=Load())], keywords=[]), attr='where', ctx=Load()), args=[Compare(left=Attribute(value=Name(id='ClothingItem', ctx=Load()), attr='id', ctx=Load()), ops=[Eq()], comparators=[Name(id='clothing_id', ctx=Load())])], keywords=[]), attr='options', ctx=Load()), args=[Call(func=Name(id='selectinload', ctx=Load()), args=[Attribute(value=Name(id='ClothingItem', ctx=Load()), attr='item_images', ctx=Load())], keywords=[])], keywords=[])], keywords=[]), attr='first', ctx=Load()), args=[], keywords=[]) If Return: Name(id='result', ctx=Load()) def get_clothing_item_by_image_url(image_url, user_id, db): Expression: Constant(value='\\n    Get one clothing item based on its image URL\\n    ') Assign: Name(id='query', ctx=Store()) = Call(func=Attribute(value=Call(func=Attribute(value=Call(func=Attribute(value=Call(func=Attribute(value=Call(func=Attribute(value=Call(func=Name(id='Select', ctx=Load()), args=[Name(id='ClothingItem', ctx=Load())], keywords=[]), attr='join', ctx=Load()), args=[Attribute(value=Name(id='ClothingItem', ctx=Load()), attr='item_images', ctx=Load())], keywords=[]), attr='where', ctx=Load()), args=[Compare(left=Attribute(value=Name(id='ItemImage', ctx=Load()), attr='url', ctx=Load()), ops=[Eq()], comparators=[Name(id='image_url', ctx=Load())])], keywords=[]), attr='join', ctx=Load()), args=[Attribute(value=Name(id='ClothingItem', ctx=Load()), attr='colors', ctx=Load())], keywords=[]), attr='join', ctx=Load()), args=[Attribute(value=Name(id='ClothingItemColor', ctx=Load()), attr='color', ctx=Load())], keywords=[]), attr='options', ctx=Load()), args=[Call(func=Attribute(value=Call(func=Name(id='selectinload', ctx=Load()), args=[Attribute(value=Name(id='ClothingItem', ctx=Load()), attr='colors', ctx=Load())], keywords=[]), attr='selectinload', ctx=Load()), args=[Attribute(value=Name(id='ClothingItemColor', ctx=Load()), attr='color', ctx=Load())], keywords=[]), Call(func=Name(id='selectinload', ctx=Load()), args=[Attribute(value=Name(id='ClothingItem', ctx=Load()), attr='type', ctx=Load())], keywords=[])], keywords=[]) Assign: Name(id='result', ctx=Store()) = Call(func=Attribute(value=Call(func=Attribute(value=Name(id='db', ctx=Load()), attr='scalars', ctx=Load()), args=[Name(id='query', ctx=Load())], keywords=[]), attr='first', ctx=Load()), args=[], keywords=[]) If Return: Name(id='result', ctx=Load()) def delete_clothing_item(clothing_id, db): Expression: Constant(value='\\n    Deletes a clothing based on an id\\n    ') Assign: Name(id='db_clothing', ctx=Store()) = Call(func=Attribute(value=Call(func=Attribute(value=Name(id='db', ctx=Load()), attr='scalars', ctx=Load()), args=[Call(func=Attribute(value=Call(func=Name(id='Select', ctx=Load()), args=[Name(id='ClothingItem', ctx=Load())], keywords=[]), attr='where', ctx=Load()), args=[Compare(left=Attribute(value=Name(id='ClothingItem', ctx=Load()), attr='id', ctx=Load()), ops=[Eq()], comparators=[Name(id='clothing_id', ctx=Load())])], keywords=[])], keywords=[]), attr='first', ctx=Load()), args=[], keywords=[]) If Expression: Call(func=Attribute(value=Name(id='db', ctx=Load()), attr='delete', ctx=Load()), args=[Name(id='db_clothing', ctx=Load())], keywords=[]) Expression: Call(func=Attribute(value=Name(id='db', ctx=Load()), attr='commit', ctx=Load()), args=[], keywords=[]) Return: Dict(keys=[], values=[]) def delete_clothing_item(image_url, user_id, db): Expression: Constant(value='\\n    Deletes a clothing based on an image_url\\n    ') Assign: Name(id='db_clothing', ctx=Store()) = Call(func=Attribute(value=Call(func=Attribute(value=Name(id='db', ctx=Load()), attr='scalars', ctx=Load()), args=[Call(func=Attribute(value=Call(func=Attribute(value=Call(func=Name(id='Select', ctx=Load()), args=[Name(id='ClothingItem', ctx=Load())], keywords=[]), attr='join', ctx=Load()), args=[Name(id='ItemImage', ctx=Load())], keywords=[]), attr='where', ctx=Load()), args=[Compare(left=Attribute(value=Name(id='ItemImage', ctx=Load()), attr='url', ctx=Load()), ops=[Eq()], comparators=[Name(id='image_url', ctx=Load())])], keywords=[])], keywords=[]), attr='first', ctx=Load()), args=[], keywords=[]) If Expression: Call(func=Attribute(value=Name(id='db', ctx=Load()), attr='delete', ctx=Load()), args=[Name(id='db_clothing', ctx=Load())], keywords=[]) Expression: Call(func=Attribute(value=Name(id='db', ctx=Load()), attr='commit', ctx=Load()), args=[], keywords=[]) Return: Dict(keys=[], values=[]) def update_clothing_item(clothing_id, clothing_item, db): Expression: Constant(value='\\n    Update a clothing item\\n    ') Assign: Name(id='query', ctx=Store()) = Call(func=Attribute(value=Call(func=Attribute(value=Call(func=Name(id='Update', ctx=Load()), args=[Name(id='ClothingItem', ctx=Load())], keywords=[]), attr='where', ctx=Load()), args=[Compare(left=Attribute(value=Name(id='ClothingItem', ctx=Load()), attr='id', ctx=Load()), ops=[Eq()], comparators=[Name(id='clothing_id', ctx=Load())])], keywords=[]), attr='values', ctx=Load()), args=[], keywords=[keyword(value=Call(func=Attribute(value=Name(id='clothing_item', ctx=Load()), attr='model_dump', ctx=Load()), args=[], keywords=[]))]) Assign: Name(id='result', ctx=Store()) = Call(func=Attribute(value=Name(id='db', ctx=Load()), attr='execute', ctx=Load()), args=[Name(id='query', ctx=Load())], keywords=[]) Expression: Call(func=Attribute(value=Name(id='db', ctx=Load()), attr='commit', ctx=Load()), args=[], keywords=[]) If Return: Dict(keys=[Constant(value='message')], values=[Constant(value='Clothing item updated successfully')]) def update_clothing_item_by_url(image_url, clothing_item, db): Expression: Constant(value='\\n    Update a clothing item based on an image_url\\n    ') Assign: Name(id='db_item_image', ctx=Store()) = Call(func=Attribute(value=Call(func=Attribute(value=Call(func=Attribute(value=Name(id='db', ctx=Load()), attr='query', ctx=Load()), args=[Name(id='ItemImage', ctx=Load())], keywords=[]), attr='filter', ctx=Load()), args=[Compare(left=Attribute(value=Name(id='ItemImage', ctx=Load()), attr='url', ctx=Load()), ops=[Eq()], comparators=[Name(id='image_url', ctx=Load())])], keywords=[]), attr='first', ctx=Load()), args=[], keywords=[]) If Assign: Name(id='clothing_id', ctx=Store()) = Attribute(value=Name(id='db_item_image', ctx=Load()), attr='clothing_item_id', ctx=Load()) Assign: Name(id='query', ctx=Store()) = Call(func=Attribute(value=Call(func=Attribute(value=Call(func=Name(id='Update', ctx=Load()), args=[Name(id='ClothingItem', ctx=Load())], keywords=[]), attr='where', ctx=Load()), args=[Compare(left=Attribute(value=Name(id='ClothingItem', ctx=Load()), attr='id', ctx=Load()), ops=[Eq()], comparators=[Name(id='clothing_id', ctx=Load())])], keywords=[]), attr='values', ctx=Load()), args=[], keywords=[keyword(value=Call(func=Attribute(value=Name(id='clothing_item', ctx=Load()), attr='model_dump', ctx=Load()), args=[], keywords=[keyword(arg='exclude_unset', value=Constant(value=True))]))]) Assign: Name(id='result', ctx=Store()) = Call(func=Attribute(value=Name(id='db', ctx=Load()), attr='execute', ctx=Load()), args=[Name(id='query', ctx=Load())], keywords=[]) Expression: Call(func=Attribute(value=Name(id='db', ctx=Load()), attr='commit', ctx=Load()), args=[], keywords=[]) If Return: Dict(keys=[Constant(value='message')], values=[Constant(value='Clothing item updated successfully')]) def upload_image(file, IMAGEDIR): Assign: Name(id='filename', ctx=Store()) = JoinedStr(values=[FormattedValue(value=Call(func=Name(id='uuid4', ctx=Load()), args=[], keywords=[]), conversion=-1), Constant(value='.'), FormattedValue(value=Subscript(value=Call(func=Attribute(value=Attribute(value=Name(id='file', ctx=Load()), attr='filename', ctx=Load()), attr='split', ctx=Load()), args=[Constant(value='.')], keywords=[]), slice=UnaryOp(op=USub(), operand=Constant(value=1)), ctx=Load()), conversion=-1)]) Assign: Name(id='file_path', ctx=Store()) = Call(func=Attribute(value=Attribute(value=Name(id='os', ctx=Load()), attr='path', ctx=Load()), attr='join', ctx=Load()), args=[Name(id='IMAGEDIR', ctx=Load()), Name(id='filename', ctx=Load())], keywords=[]) With Return: Name(id='filename', ctx=Load()) def add_clothing_item(user_id, name, description, colours, size, type, brand_id, file, db): If Assign: Name(id='type_id', ctx=Store()) = Call(func=Attribute(value=Call(func=Attribute(value=Name(id='db', ctx=Load()), attr='scalars', ctx=Load()), args=[Call(func=Attribute(value=Call(func=Name(id='Select', ctx=Load()), args=[Attribute(value=Name(id='Type', ctx=Load()), attr='id', ctx=Load())], keywords=[]), attr='where', ctx=Load()), args=[Compare(left=Attribute(value=Name(id='Type', ctx=Load()), attr='name', ctx=Load()), ops=[Eq()], comparators=[Name(id='type', ctx=Load())])], keywords=[])], keywords=[]), attr='first', ctx=Load()), args=[], keywords=[]) Assign: Name(id='clothing_item_dict', ctx=Store()) = Dict(keys=[Constant(value='name'), Constant(value='description'), Constant(value='size'), Constant(value='user_id'), Constant(value='type_id'), Constant(value='brand_id')], values=[Name(id='name', ctx=Load()), Name(id='description', ctx=Load()), Name(id='size', ctx=Load()), Name(id='user_id', ctx=Load()), Name(id='type_id', ctx=Load()), Name(id='brand_id', ctx=Load())]) Assign: Name(id='db_clothing_item', ctx=Store()) = Call(func=Name(id='ClothingItem', ctx=Load()), args=[], keywords=[keyword(value=Name(id='clothing_item_dict', ctx=Load()))]) Expression: Call(func=Attribute(value=Name(id='db', ctx=Load()), attr='add', ctx=Load()), args=[Name(id='db_clothing_item', ctx=Load())], keywords=[]) Expression: Call(func=Attribute(value=Name(id='db', ctx=Load()), attr='flush', ctx=Load()), args=[], keywords=[]) Assign: Name(id='image_filename', ctx=Store()) = Call(func=Name(id='upload_image', ctx=Load()), args=[Name(id='file', ctx=Load()), Name(id='IMAGEDIR', ctx=Load())], keywords=[]) Assign: Name(id='db_item_image', ctx=Store()) = Call(func=Name(id='ItemImage', ctx=Load()), args=[], keywords=[keyword(arg='url', value=JoinedStr(values=[FormattedValue(value=Name(id='image_filename', ctx=Load()), conversion=-1)])), keyword(arg='clothing_item', value=Name(id='db_clothing_item', ctx=Load()))]) Expression: Call(func=Attribute(value=Name(id='db', ctx=Load()), attr='add', ctx=Load()), args=[Name(id='db_item_image', ctx=Load())], keywords=[]) Assign: Name(id='colors_list', ctx=Store()) = ListComp(elt=Call(func=Attribute(value=Call(func=Attribute(value=Name(id='color_name', ctx=Load()), attr='strip', ctx=Load()), args=[], keywords=[]), attr='lower', ctx=Load()), args=[], keywords=[]), generators=[comprehension(target=Name(id='color_name', ctx=Store()), iter=Call(func=Attribute(value=Name(id='colours', ctx=Load()), attr='split', ctx=Load()), args=[Constant(value=',')], keywords=[]), ifs=[], is_async=0)]) For Expression: Call(func=Attribute(value=Name(id='db', ctx=Load()), attr='commit', ctx=Load()), args=[], keywords=[]) Expression: Call(func=Attribute(value=Name(id='db', ctx=Load()), attr='refresh', ctx=Load()), args=[Name(id='db_clothing_item', ctx=Load())], keywords=[]) Expression: Call(func=Attribute(value=Name(id='db', ctx=Load()), attr='refresh', ctx=Load()), args=[Name(id='db_item_image', ctx=Load())], keywords=[]) Return: Dict(keys=[Constant(value='clothing_item_id'), Constant(value='clothing_item_name'), Constant(value='image_url')], values=[Attribute(value=Name(id='db_clothing_item', ctx=Load()), attr='id', ctx=Load()), Attribute(value=Name(id='db_clothing_item', ctx=Load()), attr='name', ctx=Load()), Attribute(value=Name(id='db_item_image', ctx=Load()), attr='url', ctx=Load())])\n"
     ]
    }
   ],
   "source": [
    "print(query2_answer[1].metadata['source'])\n",
    "print(query2_answer[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "query3 = \"get single user details\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "query3_answer = library.similarity_search(query3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smarderobe\\server\\app\\routers\\user_router.py\n",
      "@router.get('/{user_id}', status_code=200)\n",
      "def list_users(user_id: int, db: Session=Depends(get_db)):\n",
      "    \"\"\"\n",
      "    Fetches one user based on user_id\n",
      "    \"\"\"\n",
      "    result = db.scalars(select(User).where(User.id == user_id).options(\n",
      "        selectinload(User.profile))).first()\n",
      "    if not result:\n",
      "        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\n",
      "            'No users login credentials found')\n",
      "    return result\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(query3_answer[0].metadata['source'])\n",
    "print(query3_answer[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smarderobe\\server\\app\\routers\\user_router.py\n",
      "@router.get('/{user_id}', status_code=200)\n",
      "def list_users(user_id: int, db: Session=Depends(get_db)):\n",
      "    \"\"\"\n",
      "    Fetches one user based on user_id\n",
      "    \"\"\"\n",
      "    result = db.scalars(select(User).where(User.id == user_id).options(\n",
      "        selectinload(User.profile))).first()\n",
      "    if not result:\n",
      "        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\n",
      "            'No users login credentials found')\n",
      "    return result\n",
      "\n",
      "\n",
      "\n",
      "Smarderobe\\server\\app\\routers\\user_router.py\n",
      "@router.get('/', status_code=200)\n",
      "def list_users(db: Session=Depends(get_db)):\n",
      "    \"\"\"\n",
      "    Fetches all users\n",
      "    \"\"\"\n",
      "    result = db.scalars(select(User).options(selectinload(User.profile))).all()\n",
      "    if not result:\n",
      "        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\n",
      "            'No users login credentials found')\n",
      "    return result\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for answer in query3_answer:\n",
    "    print(answer.metadata[\"source\"])\n",
    "    print(answer.page_content)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "query4_answer = library.similarity_search(\"find all missmatched functions names and function descriptions\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smarderobe\\server\\alembic\\versions\\3eab37b818e9_check.py\n",
      "summary\n",
      "3eab37b818e9_check.py\n",
      "This file is an Alembic migration script with the revision identifier '3eab37b818e9' and a down revision of '5f630b6a9222'. It includes placeholders for both `upgrade()` and `downgrade()` functions, but these functions currently contain no operations and are marked to be adjusted with appropriate Alembic commands. The file also imports necessary modules such as Alembic, SQLAlchemy, and typing annotations for variable declarations.\n",
      "\n",
      "\n",
      "Smarderobe\\server\\app\\database\\__init__.py\n",
      "summary\n",
      "__init__.py\n",
      "As there is no code provided in your request, I'm unable to provide a summary. Please provide the code content you need summarized.\n",
      "\n",
      "\n",
      "Smarderobe\\server\\app\\database\\schemas\\images_schema.py\n",
      "summary\n",
      "images_schema.py\n",
      "There is no file content provided in your request. Please provide the content or details of the file you'd like summarized.\n",
      "\n",
      "\n",
      "Smarderobe\\server\\app\\routers\\__init__.py\n",
      "summary\n",
      "__init__.py\n",
      "You have not provided the details of the file you want to summarize. Please provide the contents or details of the file, so I can assist you accordingly.\n",
      "\n",
      "\n",
      "Smarderobe\\server\\app\\routers\\type_router.py\n",
      "summary\n",
      "type_router.py\n",
      "The file defines a FastAPI router to handle HTTP GET requests at the root (\"/\") URL endpoint for listing all clothing types from a database. It utilizes SQLAlchemy for database operations, specifically performing a SELECT query that eagerly loads related 'body_section' data from the 'Type' model. If no data is found, it raises an HTTP 404 error. Dependencies are managed through a dependency function 'get_db' that presumably retrieves the database session.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for answer in query4_answer:\n",
    "    print(answer.metadata[\"source\"])\n",
    "    print(answer.metadata[\"type\"])\n",
    "    print(answer.metadata[\"name\"])\n",
    "    print(answer.page_content)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_fiels_query = library.similarity_search(\"no file content\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smarderobe\\server\\app\\database\\schemas\\images_schema.py\n",
      "summary\n",
      "images_schema.py\n",
      "There is no file content provided in your request. Please provide the content or details of the file you'd like summarized.\n",
      "\n",
      "\n",
      "Smarderobe\\server\\app\\routers\\__init__.py\n",
      "summary\n",
      "__init__.py\n",
      "You have not provided the details of the file you want to summarize. Please provide the contents or details of the file, so I can assist you accordingly.\n",
      "\n",
      "\n",
      "Smarderobe\\server\\app\\database\\__init__.py\n",
      "summary\n",
      "__init__.py\n",
      "As there is no code provided in your request, I'm unable to provide a summary. Please provide the code content you need summarized.\n",
      "\n",
      "\n",
      "Smarderobe\\server\\alembic\\versions\\3eab37b818e9_check.py\n",
      "summary\n",
      "3eab37b818e9_check.py\n",
      "This file is an Alembic migration script with the revision identifier '3eab37b818e9' and a down revision of '5f630b6a9222'. It includes placeholders for both `upgrade()` and `downgrade()` functions, but these functions currently contain no operations and are marked to be adjusted with appropriate Alembic commands. The file also imports necessary modules such as Alembic, SQLAlchemy, and typing annotations for variable declarations.\n",
      "\n",
      "\n",
      "Smarderobe\\server\\app\\routers\\type_router.py\n",
      "summary\n",
      "type_router.py\n",
      "The file defines a FastAPI router to handle HTTP GET requests at the root (\"/\") URL endpoint for listing all clothing types from a database. It utilizes SQLAlchemy for database operations, specifically performing a SELECT query that eagerly loads related 'body_section' data from the 'Type' model. If no data is found, it raises an HTTP 404 error. Dependencies are managed through a dependency function 'get_db' that presumably retrieves the database session.\n",
      "\n",
      "\n",
      "Smarderobe\\server\\app\\database\\models\\__init__.py\n",
      "summary\n",
      "__init__.py\n",
      "The file serves as a central import hub for an Alembic setup, facilitating easier management of imports in the environment configuration by centrally importing various models such as ClothingItem, Address, BodySection, Brand, Category, and others related to an application managing clothing items, their categories, seasons, associated images, and user profiles, among other entities. This approach avoids modifying imports directly in Alembic's `env.py`.\n",
      "\n",
      "\n",
      "Smarderobe\\server\\alembic\\versions\\3eab37b818e9_check.py\n",
      "function\n",
      "upgrade\n",
      "def upgrade() ->None:\n",
      "    pass\n",
      "\n",
      "\n",
      "\n",
      "Smarderobe\\server\\alembic\\versions\\8cd4ecbd3e80_add_color_bridge.py\n",
      "summary\n",
      "8cd4ecbd3e80_add_color_bridge.py\n",
      "This file contains an Alembic migration script with revision ID `8cd4ecbd3e80` that revises from version `31ed8a88e96c`. The migration aims to modify schema related to `clothing_items` and `item_images` tables. In the `upgrade` function, it removes a column named 'colours' from `clothing_items` table, drops an existing foreign key constraint on `item_images`, and adds a new foreign key from `item_images` to `clothing_items`. The `downgrade` function reverses these changes: it reinstates the foreign key constraint with additional properties, adds back the 'colours' column to `clothing_items`, and drops the newly added foreign key constraint from the `upgrade` function.\n",
      "\n",
      "\n",
      "Smarderobe\\server\\alembic\\versions\\3eab37b818e9_check.py\n",
      "function\n",
      "downgrade\n",
      "def downgrade() ->None:\n",
      "    pass\n",
      "\n",
      "\n",
      "\n",
      "Smarderobe\\server\\app\\database\\schemas\\__init__.py\n",
      "summary\n",
      "__init__.py\n",
      "The file imports various schema classes related to an e-commerce or retail application dealing with users, clothing items, and profiles. It includes schema definitions for addresses, body sections, brands, categories, genders, seasons, clothing items, users, and user profiles. Each schema likely defines the structure of data for their respective entities in the system, including specific \"out\" schemas for output data formatting and specialized schemas for operations like updating user profiles or clothing items, and handling user authentication and password reset processes.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for answer in empty_fiels_query:\n",
    "    print(answer.metadata[\"source\"])\n",
    "    print(answer.metadata[\"type\"])\n",
    "    print(answer.metadata[\"name\"])\n",
    "    print(answer.page_content)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
